<html>

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="./github-markdown.css">
  <style>
  body {
    background-color: #fbfbfb;
    margin: 0;
  }
  .markdown-body {
    box-sizing: border-box;
    margin: 0 auto;
    padding: 45px;
    overflow-x:scroll;
    max-width:900px;
    background-color: #ffffff;
    font-family: sans-serif !important;
  }

  audio {
    width:270px;
  }

  p {
    text-align:justify;
  }

  .samples {
      padding-top: 1em;
      padding-bottom: 1em;
  }

  .sample span {
    display: block;
    padding-right:10px;
  }

  .sample audio {
    display: block;
    padding-right:10px;
  }

  .sample {
      display:flex;
      align-items: center;
      justify-content: flex-start;
      padding-top: 1em;
      padding-bottom:2em;
  }

  .center {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 50%;
  }

  /* .sample span:nth-of-type(even) {
    padding-left:15px;
  }
  .lang>.sample span:nth-of-type(odd) {
    width:130px;
  } */
  </style>
  <title>End-to-end Binaural Speech Synthesis</title>
</head>

<body>
  <section class="markdown-body">
    <h1>End-to-end Binaural Speech Synthesis</h1>
    <!-- <p>We present here audio samples for the causal Demucs model trained on the
      <a href="https://github.com/microsoft/DNS-Challenge">DNS challenge dataset</a> as presented
      in the paper <a href="https://arxiv.org/abs/2006.12847">Real Time Speech Enhancement in the Waveform Domain</a>. 
      We used the
      causal Demucs with H=64, Revecho augmentation with partial dereverberation
      (10% of reverb kept), and adding back 1% of the dry signal.
    </p> -->
    <p>In this work, we aim to realize a binaural communication system, which is capable of (a) encoding transmitter audio into a low-bitrate neural code, and (b) synthesizing binaural audio from these codes including environmental factors such as room reverb and noise floor.</p>

    <img src="./model.png" alt="Model illustration." style="width:640px;" class="center">
    
    <h2>Audio samples</h2>
    Please use headphones to listen to the following audio samples.


    <section class="samples lang">
      <b>Sample 1: Pay attention to how the "baseline" and the "decoder-only" lack the environmental sounds, which are present in "ground truth" and "proposed".</b>
      <article class="sample">
        <span>Input mono speech</span>
          <audio controls>
            <source src="audio/baseline/eval000/mono.wav" type="audio/wav"></audio>
        <span>Baseline</span>
          <audio controls>
            <source src="audio/baseline/eval000/est.wav" type="audio/wav"></audio>
        <span>Decoder only</span>
          <audio controls>
            <source src="audio/decoder-only/eval000/est.wav" type="audio/wav"></audio>
        <span>Proposed</span>
          <audio controls>
            <source src="audio/proposed/eval000/est.wav" type="audio/wav"></audio>
        <span>Ground truth</span>
          <audio controls>
            <source src="audio/baseline/eval000/gnd.wav" type="audio/wav"></audio>
      </article>
      <b>Sample 2: Pay attention to the tiny sounds of stepping shoes and rubbing clothes, which the "baseline" and the "decoder-only" lack, while present in "ground truth" and "proposed".</b>
      <article class="sample">
        <span>Input mono speech</span>
          <audio controls>
            <source src="audio/baseline/eval072/mono.wav" type="audio/wav"></audio>
        <span>Baseline</span>
          <audio controls>
            <source src="audio/baseline/eval072/est.wav" type="audio/wav"></audio>
        <span>Decoder only</span>
          <audio controls>
            <source src="audio/decoder-only/eval072/est.wav" type="audio/wav"></audio>
        <span>Proposed</span>
          <audio controls>
            <source src="audio/proposed/eval072/est.wav" type="audio/wav"></audio>
        <span>Ground truth</span>
          <audio controls>
            <source src="audio/baseline/eval072/gnd.wav" type="audio/wav"></audio>
      </article>
      <b>Sample 3: Although we focused on speech, we also tested with singing input. The "proposed" suffers from data mismatch and the quality was greatly degraded. However, it still captured the environmental sounds like room reverb and noise.</b>
      <article class="sample">
        <span>Input mono speech</span>
          <audio controls>
            <source src="audio/baseline/eval132/mono.wav" type="audio/wav"></audio>
        <span>Baseline</span>
          <audio controls>
            <source src="audio/baseline/eval132/est.wav" type="audio/wav"></audio>
        <span>Decoder only</span>
          <audio controls>
            <source src="audio/decoder-only/eval132/est.wav" type="audio/wav"></audio>
        <span>Proposed</span>
          <audio controls>
            <source src="audio/proposed/eval132/est.wav" type="audio/wav"></audio>
        <span>Ground truth</span>
          <audio controls>
            <source src="audio/baseline/eval132/gnd.wav" type="audio/wav"></audio>
      </article>
    </section>


    
</body>

</html>
